[{"type": "human", "data": {"content": "**Job Responsibilities:**\n\n* Develop and deploy event-driven pipeline architectures for distributed ingestion and processing\n* Extend and optimize data pipelines, data lake, and data warehouse to support growing data sources and processing needs\n* Collaborate with data engineers to review and approve pull requests\n* Improve and optimize information models for BI and data science needs across multiple teams, systems, and products\n* Create robust, reusable, and scalable tools using appropriate software and languages\n* Build end-to-end data solutions within client's cloud environment\n* Work closely with Data Scientists, Analysts, and Users through peer programming, code reviews, and technical consultations\n* Partner with engineering, product, and business stakeholders to build technical solutions aligned with business objectives\n\n**Required Hard Skills:**\n\n* Experience in a similar Data Engineering role with a modern tech stack\n* Strong working knowledge of the Azure stack (storage, networking, terraform)\n* Hands-on experience with SQL, Python, Pyspark, Data Bricks/Notebooks, DBT, Airflow, and Data Factory\n* Experience with data infrastructure, CI/CD pipelines, automated testing, and modern DevOps practices\n* Proven track record in building, extending, and maintaining robust data pipelines, secure data stores, and efficient streaming and batch data environments\n* Experience in building, scaling, and monitoring resilient distributed systems\n* Proficient in creating technical architectures, concepts, designs, and approaches\n\n**Experience Requirements:**\n\n* Proven experience in a similar Data Engineering role\n* 3+ years of experience in data engineering or a related field\n\n**Soft Skills in Context:**\n\n* Excellent communication and interpersonal skills\n* Strong teamwork and collaboration abilities\n* Problem-solving and analytical thinking\n* Ability to work independently and as part of a team\n* Attention to detail and accuracy", "additional_kwargs": {}, "type": "human", "name": null, "id": null, "example": false}}, {"type": "ai", "data": {"content": "**Baseline Knowledge Requirements**\n\n**Educational Background:**\n\n* Not specified\n\n**Programming Proficiency:**\n\n* SQL\n* Python\n* Pyspark\n\n**Technical Experience and Knowledge:**\n\n* Azure stack (storage, networking, terraform)\n* Data Bricks/Notebooks\n* DBT\n* Airflow\n* Data Factory\n* Data infrastructure\n* CI/CD pipelines\n* Automated testing\n* DevOps practices\n* Building, extending, and maintaining data pipelines\n* Secure data stores\n* Streaming and batch data environments\n* Resilient distributed systems\n* Technical architecture design\n\n**Language and Communication Skills:**\n\n* Excellent communication and interpersonal skills\n\n**Personal Qualities:**\n\n* Strong teamwork and collaboration abilities\n* Problem-solving and analytical thinking\n* Ability to work independently and as part of a team\n* Attention to detail and accuracy\n\n**Specific Experience or Priority Considerations:**\n\n* Proven experience in a similar Data Engineering role\n* 3+ years of experience in data engineering or a related field", "additional_kwargs": {}, "type": "ai", "name": null, "id": null, "example": false}}]