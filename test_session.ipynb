{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FSA\\fsa-simpleqt\\backend-simpleqt\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import prompt template\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# import the json oupput parser from the langchain core\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    }
   ],
   "source": [
    "# define the parser object\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Import API key\n",
    "load_dotenv()\n",
    "\n",
    "# Define the google api key\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "os.environ['CLAUDE_API_KEY'] = os.getenv('CLAUDE_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "CLAUDE_API_KEY = os.environ.get(\"CLAUDE_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Prompts,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, convert_system_message_to_human=True, api_key=GOOGLE_API_KEY, request_timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize JD\n",
    "prompt_jd = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                Let's think step by step.\n",
    "                Act as a HR manager and analyze Job Description: {jd}\n",
    "                Analyzing guide:\n",
    "                Let's think step by step.\n",
    "                Respond using only the provided information and do not rely on your basic knowledge.\n",
    "                Only use the given data to determine educational qualifications and certificates; do not make assumptions about these qualifications.\n",
    "                However, you are allowed to combine the provided details to draw logical conclusions about soft skills.\n",
    "                Please structure the JSON output as follows: {\"Job Description\": \"\", \"Requirements\": \"\"}\n",
    "                Next, you will be given CVs. Analyze the CVs and determine if the candidates meet the job requirements. Be fair and objective in your assessment.\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template([\"{jd}\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match CV to JD\n",
    "prompt_match = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                I have a curriculum vitae (CV) for a candidate, and the above job description (JD) for a specific position. \n",
    "                This is the CV: \n",
    "                {cv}\n",
    "                Based on the provided CV and JD, I need an analysis that examines how well the candidate's qualifications match the job requirements. This analysis should be summarized in a JSON file, with special attention to:\n",
    "                - The match with the base requirements outlined in the JD, including education, technical skills, and relevant experiences.\n",
    "                - A detailed description of any additional qualifications the candidate possesses that align with the JD. This should focus on research experience, communication skills, and any other notable achievements, directly inserted into the 'bonus_qualifications_met' field in the JSON.\n",
    "                - An estimated match percentage reflecting how closely the candidate fits the job description, based on the analysis.\n",
    "                - The total count of bonus qualifications identified in the candidate's background.\n",
    "\n",
    "                Please structure the JSON output as follows:\n",
    "\n",
    "                ```json\n",
    "                {\n",
    "                \"match_with_base_requirements\": \"Include a detailed analysis here, linking the candidate's qualifications directly to the job's base requirements.\",\n",
    "                \"bonus_qualifications_met\": \"Insert detailed descriptions of the candidate's bonus qualifications here, emphasizing areas such as research experience, communication skills, and other relevant achievements.\",\n",
    "                \"candidate_match_percentage\": \"Provide an estimated match percentage here based on the analysis.\",\n",
    "                \"number_of_bonus_qualifications\": \"Indicate the total number of detailed bonus qualifications identified.\"\n",
    "                }\n",
    "                \"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template([\"{cv}\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd = \"\"\"\n",
    "Job Description for AI Engineer Fresher at GMO-Z.com RUNSYSTEM\n",
    "1) Job Description:\n",
    "Research and develop new AI solutions and technologies for the company's software projects using artificial intelligence technology.\n",
    "Participate in knowledge sharing seminars and regular reports.\n",
    "Undertake other projects and tasks as required by the direct manager.\n",
    "2) Requirements:\n",
    "Knowledge and skills:\n",
    "Graduate from a regular university majoring in Computer Science, Data Science, or Artificial Intelligence.\n",
    "Proficiency in one of the programming languages such as Python, C++, etc.\n",
    "Experience working with Git, Docker.\n",
    "Understand the frameworks: Tensorflow/keras, pytorch.\n",
    "Understand the architectures CNN, RNN, LSTM, Transformer.\n",
    "Understand the SSH network protocol.\n",
    "Other requirements:\n",
    "Read and understand English in the field of Information Technology.\n",
    "Be interested in and passionate about researching problems related to face processing systems.\n",
    "Have a spirit of hard work, responsibility for assigned tasks and long-term commitment to the company.\n",
    "Good communication skills, ability to work independently and in a team.\n",
    "Experience: Experience in participating in AI projects related to face processing systems is an advantage.\n",
    "Priority:\n",
    "Candidates who have researched AI/Machine Learning topics in laboratories or have international publications and scientific awards are an advantage.\n",
    "Good communication English.\n",
    "3) Benefits:\n",
    "Salary: Up to 10,000,000 VND/month.\n",
    "Performance bonus, Project bonus and other bonuses (Achievement bonus, Outstanding individual bonus, Foreign language/Professional certificate bonus).\n",
    "Work directly with Japanese clients. Opportunity to Onsite in Japan (when becoming a full-time employee).\n",
    "Enjoy other benefits such as: Monthly team building, annual vacation, periodic health check-up...\n",
    "All regimes in accordance with the Labor Law of Vietnam (Social Insurance, Health Insurance, Unemployment Insurance, ...).\n",
    "Annual leave and other holidays according to the regulations of the Government of Vietnam.\n",
    "Young and dynamic working environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = \"\"\"\n",
    "DAO NGOC HUY FPT University AI Intern\\n\\n(cid:17) 28-02-2002\\n\\n(cid:211) 0913596890\\n\\ng Huy Dao\\n\\n(cid:135) Dao Ngoc Huy\\n\\ndnhuy2802@gmail.com\\n\\nDao Ngoc Huy\\n\\nMAIN OBJECT\\n\\nSTRENGTHS\\n\\nUnderstand the process of an AI project in the company.\\n\\nProblem-Solving: Adept at analyzing complex problems.\\n\\nParticipate in programming support for AI projects or join new projects.\\n\\nCommunication: Eloquent, good communication and teamwork.\\n\\nWork as a fresher at the company after internship.\\n\\nSelf-learing: Discover and practice new knowledge yourself.\\n\\nEXPERIENCE\\n\\n2023\\n\\nZalo AI Challenge 2023\\n\\nCompetition\\n\\nJoin track Advertising Banner Generation • Approach the problem in two directions: Using Diffusion Stable and using Prompt Engineering\\n\\n2023\\n\\nFPT AI Challenge 2023\\n\\nCompetition\\n\\nLearning NLP, build Transformer from scratch using Python. • Make idea and apply fine-tuning model on Huggingface.\\n\\n2023\\n\\nFPT Digital Race 2023\\n\\nCompetition\\n\\nBe the team leader and achieve 3rd place overall. • Data-centric AI: Using Augmentation data methods for images collected from self-driving vehicles. • Handle imbalanced data before training the model.\\n\\n2023\\n\\nResearch: Comparing different methods on imputation task of Time series\\n\\nUniversity • Apply Machine Learning methods: Linear Regression, KNN, SVM, Decision Tree, Random Forest, Ada\\n\\nBoost, ...\\n\\nApply Deep Learing methods: Simple RNN, LSTM, CNN. • ML methods are built from Sklearn, DL methods are built from Keras.\\n\\n2021 - 2022\\n\\nTech Lead GDSC FPTU Da Nang Club\\n\\nUniversity\\n\\nManage and coordinate work for members. • Collaborate, make content and work with speaker in technology events, webinars, and workshops. • Learning points: Assign appropriate work to members, cooperate with other teams, manage work progress and make timeline technology event.\\n\\nKNOWLEDGE Exploratory Data Analysis (EDA) - Using Pandas, Matplotlib, Seaborn to find insight into data and preprocessing table data.\\n\\nSKILLS Programing Languages: SQL, Python, JavaScript.\\n\\nMachine Learning (ML) - Have knowledge about: Linear Regression, KNN, SVN, Random Forest, Deci- sion Tree, Boosting Algorithm, Stasking,... - Using ML Algorithm for different tasks: classifying, problems related to predic- tion, filling missing data, and other problems.\\n\\nLibraries: Flask, Pandas, Matplotlib, Plotly, Scikit-learn, librosa, OpenCV...\\n\\nAI Frameworks: TensorFlow/Keras, PyTorch\\n\\nDeep Learning (DL) - CNN Architecture: Have knowledge of different CNN models. Build DenseNet and ResNet using Pytorch. - Sequence Model: RNN, LSTM, Attention, Transformer.\\n\\nTool: Docker, Weight&Bias, Tensorboard, Postman, Colab, ...\\n\\nExtract Feature - Image: Hough Transform, Edge Detector, SIFT,... - Audio: Spectrogram, RMS-E, Chroma, MFCC, HPSS ...\\n\\nBackend - Using Flask to write API. - Usìng a database such as MongoDB, or Firebase.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = \"\"\"\n",
    "Đoàn Quang Minh\\n\\nAI Intern\\n\\nquangminh57dng@gmail.com\\n\\n+84 905 070 942\\n\\n06 Đỗ Thế Chấp, Đà Nẵng\\n\\ngithub.com/Ming-doan\\n\\nlinkedin.com/in/quangminhdoan\\n\\nExperiments 06/2023 Present\\n\\nTime Series Conference Paper AI Developer\\n\\n- - - -\\n\\nExperiment in Time Series or Signal processing Building Training pipeline with Python via Colab Enhance Tuning parameters with over 2,000 runs in 8 hours Experiment in Machine Learning methods with Scikit-learn Experiment in Managing experiment results\\n\\n10/2023\\n\\nQuy Nhon AI Hackathon 2023 AI Developer\\n\\nGet notices by mentors - -\\n\\nExperiment in building and training Transformer models Experiment in building Recommendation system\\n\\n09/2023\\n\\nFPT Digital Race Competition AI Developer\\n\\nWinning Third prize - -\\n\\nBuild training & Data augmentation pipeline with Python Enhance Development cycle in AI process\\n\\n07/2023\\n\\nUnihack 2023 AI Developer & Full-stack developer\\n\\nWinning Second prize - - -\\n\\nExperiment in Object detection with YOLOv8 and TACO dataset Experiment in building AI Back-end system with Flask Experiment in building Mobile with Flutter\\n\\n05/2023 07/2023\\n\\nFace Recognition AI Developer & Full-stack developer\\n\\n- -\\n\\nExperiment in building Face Recognition solution Experiment in building AI Back-en system with Flask Experiment in building Web with ReactJS\\n\\n04/2023 Present\\n\\nEnhance Face Recognition with Ensemble Deep Learning AI Developer & AI Researcher\\n\\n-\\n\\nExperiment in building Face Recognition with SOTA models Experiment in writing scientific paper\\n\\nCertificates\\n\\nDeep Learning AI AI Deep Learning course by Andrew Ng.\\n\\n12/2023\\n\\nGDG Devfest Devfest Hackathon by GDG Mien Trung\\n\\n11/2023\\n\\nDeputy Lead at GDSC-FPTU 10/2023 Deputy Lead at GDSC FPT University Da Nang\\n\\nGoogle Solution Challenge 06/2022 Solution Challenge competition by Google Developer Student Clubs\\n\\n07/04/2003\\n\\nObjective I am currently in the third year of FPT University and major is Artificial Intelli- gence. I am a code-holic guys and experimented with serveral Freelance jobs. I will building and developing AI solution with high accuracy and efficient.\\n\\nTechnical Skills\\n\\n8/10 Python Able to build apps, AI, libraries\\n\\nTensorFlow, PyTorch 5/10 Able to build custom ML, DL models\\n\\n7/10\\n\\nGit, Github Familiar with version control tools\\n\\n8/10\\n\\nFlask, FastAPI Able to build Back-end solution for AI\\n\\n3/10 Docker Able to create simple Container\\n\\nJira, Trello Familiar with task tracking tools\\n\\n8/10\\n\\nSoft Skills Team Working Able to work with medium team size\\n\\nLeadership Able to manage a team, efforts, performance, handle mental issues\\n\\nLanguages English Archived IELTS 5.5\\n\\nJapanese Language understanding\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv3 = \"\"\"\n",
    "DIEP GIA DONG\\n\\nPERSONAL DETAILS\\n\\nName ● Nationality ● Date of Birth ● Sex ● Marital status ● Phone No. ● Email ● Github\\n\\nDIEP GIA DONG Vietnamese May, 29th 2003 Male Single (84) 356 16 91 37 diepgiadong@gmail.com github.com/DiepDong\\n\\nEDUCATIONAL BACKGROUND\\n\\nApplied Artificial intelligence - FPT Quy Nhon University, Vietnam\\n\\nPROFESSIONAL SUMMARY\\n\\nHard working, self-confidence, good communication skills. ● Work under pressure. ● High teamwork spirit and eager to learn and share. ● Sociable, friendly communication in team work.\\n\\nSOFTWARE\\n\\nDatabases etc: Qdrant.\\n\\nProgramming Languages: Python, HTML & CSS, Reactjs(basic).\\n\\nProgramming Tools: Visual Studio code, Docker, Kubernetes.\\n\\nOOAD/OOP: Object Oriented Programming (OOP).\\n\\nEDUCATIONAL EXPERIENCE\\n\\nPROJECTANDPRACTICE\\n\\nProjectname Position(s)\\n\\nSentiment classification Analysis and Front-end Developer\\n\\nDuration 6/2023 - 8/2023\\n\\nGeneral information\\n\\nCustomer: Vietnam\\n\\nTeam Size: 4 person\\n\\nDescription\\n\\nFrom input text emotion programs build AI models (output including other, Disgust, Enjoyment, Anger, Surprise, Sadness, and Fear).\\n\\nDiep Gia Dong's CV - Confidential\\n\\n1\\n\\nProject Scope\\n\\nTechnology used\\n\\nProjectname Position(s)\\n\\nGeneral information\\n\\nDescription\\n\\nProject Scope\\n\\nTechnology used\\n\\nRequirement - Design Web - Coding - Test\\n\\n▪ ▪ ▪\\n\\nPython Flask App HTML & CSS\\n\\nCoconut Mature Classification Pre-processing and Developer\\n\\nDuration 9/2023 - 12/2023\\n\\nCustomer: Vietnam\\n\\nTeam Size: 5 person\\n\\nFrom input coconut image programs build AI models (output including young coconut, mature coconut, old coconut)\\n\\nRequirement - Design Web - Coding - Test\\n\\n▪ ▪ ▪\\n\\nPython Flask APP HTML & CSS\\n\\nHOBBIES\\n\\nMusic, reading, travelling…\\n\\nDiep Gia Dong's CV - Confidential\\n\\n2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresher Web\n",
    "cv4 = \"\"\"\n",
    "Name: Emily Chen\n",
    "Email: emily.chen@email.com\n",
    "\n",
    "Summary: Enthusiastic and dedicated Computer Science graduate from Georgia Tech with a strong interest in web technologies and user experience design. Excellent problem-solving skills and a keen learner of new technologies and frameworks.\n",
    "\n",
    "Technical Skills: HTML, CSS, JavaScript, React.js, Python, MySQL, Basic PHP, Agile Methodologies\n",
    "\n",
    "Experience:\n",
    "- Developed a responsive portfolio website to showcase personal projects and academic research.\n",
    "- Collaborated with peers to create a browser-based game using JavaScript and HTML5 Canvas.\n",
    "- Volunteered to develop a website for a local non-profit, improving their event visibility and donations.\n",
    "\n",
    "Education: Bachelor's in Computer Science, Georgia Institute of Technology\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junior Web\n",
    "cv5 = \"\"\"\n",
    "Name: Jordan Taylor\n",
    "Email: jordan.taylor@email.com\n",
    "\n",
    "Summary: Passionate Software Developer with 3 years of experience in creating robust and user-centric web solutions. Adept in both front-end and back-end development with a track record of building scalable web applications. Committed to leveraging modern development practices and frameworks to achieve business goals and provide value to end-users.\n",
    "\n",
    "Technical Skills: HTML5, CSS3, JavaScript (ES6+), React, Redux, Node.js, Express, MongoDB, SQL, RESTful API Development, Version Control (Git), Unit Testing (Jest)\n",
    "\n",
    "Experience:\n",
    "- Developed and launched a responsive SPA for an online retail store, leading to a 40% increase in customer retention.\n",
    "- Collaborated in a cross-functional team to integrate RESTful services, improving data retrieval efficiency by 30%.\n",
    "- Engineered a custom CMS using Node.js and MongoDB, which enhanced content management efficiency for non-technical staff.\n",
    "- Fostered an Agile development environment, consistently meeting sprint goals and contributing to a 20% increase in overall development speed.\n",
    "\n",
    "Education: Bachelor's in Software Engineering, University of California, Berkeley\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Senior Web\n",
    "cv6 = \"\"\"\n",
    "Name: Oliver Zhang\n",
    "Email: oliver.zhang@email.com\n",
    "\n",
    "Summary: Seasoned Full-Stack Developer with 8 years of experience in building complex web applications and leading agile development teams. Specializes in end-to-end development, from database design to front-end user interfaces, with a focus on creating efficient and scalable products.\n",
    "\n",
    "Technical Skills: Full-Stack Development, React, Angular, .NET Core, Node.js, SQL Server, MongoDB, Elasticsearch, Azure Cloud Services, DevOps, Agile Scrum, Test-Driven Development\n",
    "\n",
    "Experience:\n",
    "- Led the development of a real-time analytics dashboard used by Fortune 500 companies, enhancing decision-making capabilities.\n",
    "- Drove the migration of legacy systems to modern web frameworks, reducing operational costs by 40% and improving system uptime to 99.99%.\n",
    "- Implemented DevOps practices across the organization, significantly reducing the release cycle time and improving system stability.\n",
    "\n",
    "Education: Bachelor's in Computer Science, Massachusetts Institute of Technology (MIT)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = memory.load_memory_variables({}).get(\"chat\")\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.save_context({\"input\": \"Who is the president of the USA\"}, {\"output\": \"Joe Biden\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt + Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def answer():\n",
    "#     # Create the chat message, potentially incorporating previous insights\n",
    "#     chat_history = memory.load_memory_variables({}).get(\"chat_history\")\n",
    "#     if chat_history:\n",
    "#         chat_message = prompt.format_messages(context=chat_history)\n",
    "#     else:\n",
    "#         chat_message =  prompt.format_messages()\n",
    "\n",
    "#     # Analyze with the chain\n",
    "#     result = chain.invoke(chat_message)\n",
    "\n",
    "#     # Update memory\n",
    "#     memory.save_context({\"inputs\": chat_message[0].content}, {\"output\": result.content})\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_message = prompt.format_messages(context=chat_history)\n",
    "# print(chat_message[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer().content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=ConversationBufferMemory(memory_key='chat'), prompt=ChatPromptTemplate(input_variables=['jd'], messages=[SystemMessage(content='\\n                Let\\'s think step by step.\\n                Act as a HR manager and analyze Job Description: {jd}\\n                Analyzing guide:\\n                Let\\'s think step by step.\\n                Respond using only the provided information and do not rely on your basic knowledge.\\n                Only use the given data to determine educational qualifications and certificates; do not make assumptions about these qualifications.\\n                However, you are allowed to combine the provided details to draw logical conclusions about soft skills.\\n                Please structure the JSON output as follows: {\"Job Description\": \"\", \"Requirements\": \"\"}\\n                Next, you will be given CVs. Analyze the CVs and determine if the candidates meet the job requirements. Be fair and objective in your assessment.\\n                '), HumanMessagePromptTemplate(prompt=[PromptTemplate(input_variables=['jd'], template='{jd}')])]), llm=ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.3, client= genai.GenerativeModel(\n",
       "   model_name='models/gemini-pro',\n",
       "   generation_config={}.\n",
       "   safety_settings={}\n",
       "), convert_system_message_to_human=True))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain0 = LLMChain(llm=llm, prompt=prompt_jd, memory=memory)\n",
    "chain0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=ConversationBufferMemory(memory_key='chat'), prompt=ChatPromptTemplate(input_variables=['cv'], messages=[SystemMessage(content='\\n                I have a curriculum vitae (CV) for a candidate, and the above job description (JD) for a specific position. \\n                This is the CV: \\n                {cv}\\n                Based on the provided CV and JD, I need an analysis that examines how well the candidate\\'s qualifications match the job requirements. This analysis should be summarized in a JSON file, with special attention to:\\n                - The match with the base requirements outlined in the JD, including education, technical skills, and relevant experiences.\\n                - A detailed description of any additional qualifications the candidate possesses that align with the JD. This should focus on research experience, communication skills, and any other notable achievements, directly inserted into the \\'bonus_qualifications_met\\' field in the JSON.\\n                - An estimated match percentage reflecting how closely the candidate fits the job description, based on the analysis.\\n                - The total count of bonus qualifications identified in the candidate\\'s background.\\n\\n                Please structure the JSON output as follows:\\n\\n                ```json\\n                {\\n                \"match_with_base_requirements\": \"Include a detailed analysis here, linking the candidate\\'s qualifications directly to the job\\'s base requirements.\",\\n                \"bonus_qualifications_met\": \"Insert detailed descriptions of the candidate\\'s bonus qualifications here, emphasizing areas such as research experience, communication skills, and other relevant achievements.\",\\n                \"candidate_match_percentage\": \"Provide an estimated match percentage here based on the analysis.\",\\n                \"number_of_bonus_qualifications\": \"Indicate the total number of detailed bonus qualifications identified.\"\\n                }\\n                '), HumanMessagePromptTemplate(prompt=[PromptTemplate(input_variables=['cv'], template='{cv}')])]), llm=ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.3, client= genai.GenerativeModel(\n",
       "   model_name='models/gemini-pro',\n",
       "   generation_config={}.\n",
       "   safety_settings={}\n",
       "), convert_system_message_to_human=True))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain1 = LLMChain(llm=llm, prompt=prompt_match, memory=memory)\n",
    "chain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\FSA\\fsa-simpleqt\\backend-simpleqt\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Job Description\": \"Research and develop new AI solutions and technologies for the company's software projects using artificial intelligence technology.\\nParticipate in knowledge sharing seminars and regular reports.\\nUndertake other projects and tasks as required by the direct manager.\", \"Requirements\": {\"Education\": \"Graduate from a regular university majoring in Computer Science, Data Science, or Artificial Intelligence.\", \"Skills\": [\"Proficiency in one of the programming languages such as Python, C++, etc.\", \"Experience working with Git, Docker.\", \"Understand the frameworks: Tensorflow/keras, pytorch.\", \"Understand the architectures CNN, RNN, LSTM, Transformer.\", \"Understand the SSH network protocol.\", \"Read and understand English in the field of Information Technology.\", \"Good communication skills, ability to work independently and in a team.\"], \"Experience\": \"Experience in participating in AI projects related to face processing systems is an advantage.\", \"Soft Skills\": [\"Be interested in and passionate about researching problems related to face processing systems.\", \"Have a spirit of hard work, responsibility for assigned tasks and long-term commitment to the company.\"]}\n"
     ]
    }
   ],
   "source": [
    "result0 = chain0.run(jd)\n",
    "print(result0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"match_with_base_requirements\": \"**Education:** The candidate holds a Bachelor's degree in Computer Science from MIT, which meets the JD's requirement for a bachelor's degree in a relevant field.\\n\\n**Technical Skills:** The candidate possesses a strong foundation in full-stack development, including proficiency in React, Angular, .NET Core, Node.js, SQL Server, MongoDB, Elasticsearch, Azure Cloud Services, DevOps, and Agile Scrum. This aligns well with the JD's requirement for expertise in full-stack development and familiarity with modern web frameworks and cloud services.\\n\\n**Relevant Experience:** The candidate's experience in leading the development of a real-time analytics dashboard, migrating legacy systems to modern web frameworks, and implementing DevOps practices demonstrates their ability to handle complex development projects and drive technological advancements. These experiences align with the JD's requirement for experience in full-stack development, system migration, and DevOps implementation.\",\n",
      "  \"bonus_qualifications_met\": \"**Research Experience:** The CV does not provide specific details about the candidate's research experience.\\n\\n**Communication Skills:** The CV does not provide specific examples of the candidate's communication skills.\\n\\n**Other Notable Achievements:** The candidate's leadership in implementing DevOps practices across the organization, resulting in reduced release cycle time and improved system stability, is a notable achievement that aligns with the JD's emphasis on agile development and continuous improvement.\",\n",
      "  \"candidate_match_percentage\": \"85%\",\n",
      "  \"number_of_bonus_qualifications\": \"1\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result1 = chain1.run(cv6)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({}).get(\"chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chat_memory.pkl', 'wb') as f:\n",
    "    pickle.dump(memory, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'chat_memory.pkl', 'rb') as f:\n",
    "    memory = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
